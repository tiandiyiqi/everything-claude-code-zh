# 参考：Manus 上下文工程原理精要

> 基于 Manus（2025 年 12 月被 Meta 以 20 亿美元收购的 AI 智能体公司）的上下文工程原理。

## 6 大核心原理

### 原理 1：围绕 KV-Cache 设计

> "KV-cache 命中率是生产级 AI 智能体最重要的单一指标。"

- 缓存 Token：$0.30/MTok vs 未缓存：$3/MTok（10 倍成本差异）
- 保持提示前缀稳定（单个 Token 变化即失效缓存）
- 系统提示中不放时间戳
- 上下文采用追加模式（Append-Only）

### 原理 2：遮蔽而非移除

不要动态移除工具（会破坏 KV-Cache），使用 logit masking 代替。

### 原理 3：文件系统作为外部记忆

> "Markdown 是我在磁盘上的'工作记忆'。"

```
上下文窗口 = RAM（易失，有限）
文件系统 = 磁盘（持久，无限）
```

压缩必须可恢复：保留 URL 和文件路径，即使丢弃内容。

### 原理 4：通过复述操纵注意力

> "在整个任务过程中创建和更新 todo.md，将全局计划推入模型的近期注意力范围。"

问题：约 50 次工具调用后，模型会忘记原始目标（"迷失在中间"效应）。
解决：决策前重新读取 `task_plan.md`，目标出现在注意力窗口中。

### 原理 5：保留错误记录

> "将错误的尝试留在上下文中。"

失败的操作和堆栈跟踪让模型隐式更新信念，减少重复犯错。

### 原理 6：避免被少样本学习误导

> "一致性滋生脆弱性。"

重复的操作-观察对会导致漂移和幻觉。引入受控变化，不要盲目复制模式。

## 3 大上下文策略

### 策略 1：上下文缩减

- 压缩（Compaction）：旧的工具结果保留引用/路径，近期结果保持完整
- 摘要（Summarization）：压缩到极限后生成标准化摘要

### 策略 2：上下文隔离（多智能体）

```
规划智能体 → 分配任务给子智能体
知识管理器 → 审查对话，决定文件存储
执行子智能体 → 执行任务，拥有独立上下文窗口
```

### 策略 3：上下文卸载

- 使用 <20 个原子函数
- 完整结果存储在文件系统，而非上下文
- 渐进式披露：按需加载信息

## 关键统计

| 指标 | 数值 |
|------|------|
| 平均每任务工具调用次数 | ~50 |
| 输入/输出 Token 比 | 100:1 |
| 收购价格 | 20 亿美元 |

---

**来源**: [Manus Context Engineering Blog](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus)
